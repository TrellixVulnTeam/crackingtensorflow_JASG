{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ops' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8d263544a82b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m ops.register_proto_function(ops.GraphKeys.GLOBAL_VARIABLES,\n\u001b[0m\u001b[1;32m     36\u001b[0m                             \u001b[0mproto_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariableDef\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                             \u001b[0mto_proto\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_proto\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ops' is not defined"
     ]
    }
   ],
   "source": [
    "# Exporting and Importing a MetaGraph\n",
    "\n",
    "def to_proto(self, export_scope=None):\n",
    "\n",
    "  \"\"\"Converts a `Variable` to a `VariableDef` protocol buffer.\n",
    "\n",
    "  Args:\n",
    "    export_scope: Optional `string`. Name scope to remove.\n",
    "\n",
    "  Returns:\n",
    "    A `VariableDef` protocol buffer, or `None` if the `Variable` is not\n",
    "    in the specified name scope.\n",
    "  \"\"\"\n",
    "  if (export_scope is None or\n",
    "      self._variable.name.startswith(export_scope)):\n",
    "    var_def = variable_pb2.VariableDef()\n",
    "    var_def.variable_name = ops.strip_name_scope(\n",
    "        self._variable.name, export_scope)\n",
    "    var_def.initializer_name = ops.strip_name_scope(\n",
    "        self.initializer.name, export_scope)\n",
    "    var_def.snapshot_name = ops.strip_name_scope(\n",
    "        self._snapshot.name, export_scope)\n",
    "    if self._save_slice_info:\n",
    "      var_def.save_slice_info_def.MergeFrom(self._save_slice_info.to_proto(\n",
    "          export_scope=export_scope))\n",
    "    return var_def\n",
    "  else:\n",
    "    return None\n",
    "\n",
    "@staticmethod\n",
    "def from_proto(variable_def, import_scope=None):\n",
    "  \"\"\"Returns a `Variable` object created from `variable_def`.\"\"\"\n",
    "  return Variable(variable_def=variable_def, import_scope=import_scope)\n",
    "\n",
    "ops.register_proto_function(ops.GraphKeys.GLOBAL_VARIABLES,\n",
    "                            proto_type=variable_pb2.VariableDef,\n",
    "                            to_proto=Variable.to_proto,\n",
    "                            from_proto=Variable.from_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def export_meta_graph(filename=None, collection_list=None, as_text=False):\n",
    "  \"\"\"Writes `MetaGraphDef` to save_path/filename.\n",
    "\n",
    "  Args:\n",
    "    filename: Optional meta_graph filename including the path.\n",
    "    collection_list: List of string keys to collect.\n",
    "    as_text: If `True`, writes the meta_graph as an ASCII proto.\n",
    "\n",
    "  Returns:\n",
    "    A `MetaGraphDef` proto.\n",
    "  \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "...\n",
    "with tf.Session() as sess:\n",
    "  # Use the model\n",
    "  ...\n",
    "# Export the model to /tmp/my-model.meta.\n",
    "meta_graph_def = tf.train.export_meta_graph(filename='/tmp/my-model.meta')\n",
    "\n",
    "meta_graph_def = tf.train.export_meta_graph(\n",
    "    filename='/tmp/my-model.meta',\n",
    "    collection_list=[\"input_tensor\", \"output_tensor\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# export meta graph\n",
    "\n",
    "...\n",
    "# Create a saver.\n",
    "saver = tf.train.Saver(...variables...)\n",
    "# Remember the training_op we want to run by adding it to a collection.\n",
    "tf.add_to_collection('train_op', train_op)\n",
    "sess = tf.Session()\n",
    "for step in xrange(1000000):\n",
    "    sess.run(train_op)\n",
    "    if step % 1000 == 0:\n",
    "        # Saves checkpoint, which by default also exports a meta_graph\n",
    "        # named 'my-model-global_step.meta'.\n",
    "        saver.save(sess, 'my-model', global_step=step)\n",
    "        \n",
    "        \n",
    "\n",
    "# import meta graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  new_saver = tf.train.import_meta_graph('my-save-dir/my-model-10000.meta')\n",
    "  new_saver.restore(sess, 'my-save-dir/my-model-10000')\n",
    "  # tf.get_collection() returns a list. In this example we only want the\n",
    "  # first one.\n",
    "  train_op = tf.get_collection('train_op')[0]\n",
    "  for step in xrange(1000000):\n",
    "    sess.run(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build an inference graph, export it as a meta graph:\n",
    "\n",
    "# Creates an inference graph.\n",
    "# Hidden 1\n",
    "images = tf.constant(1.2, tf.float32, shape=[100, 28])\n",
    "with tf.name_scope(\"hidden1\"):\n",
    "  weights = tf.Variable(\n",
    "      tf.truncated_normal([28, 128],\n",
    "                          stddev=1.0 / math.sqrt(float(28))),\n",
    "      name=\"weights\")\n",
    "  biases = tf.Variable(tf.zeros([128]),\n",
    "                       name=\"biases\")\n",
    "  hidden1 = tf.nn.relu(tf.matmul(images, weights) + biases)\n",
    "# Hidden 2\n",
    "with tf.name_scope(\"hidden2\"):\n",
    "  weights = tf.Variable(\n",
    "      tf.truncated_normal([128, 32],\n",
    "                          stddev=1.0 / math.sqrt(float(128))),\n",
    "      name=\"weights\")\n",
    "  biases = tf.Variable(tf.zeros([32]),\n",
    "                       name=\"biases\")\n",
    "  hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases)\n",
    "# Linear\n",
    "with tf.name_scope(\"softmax_linear\"):\n",
    "  weights = tf.Variable(\n",
    "      tf.truncated_normal([32, 10],\n",
    "                          stddev=1.0 / math.sqrt(float(32))),\n",
    "      name=\"weights\")\n",
    "  biases = tf.Variable(tf.zeros([10]),\n",
    "                       name=\"biases\")\n",
    "  logits = tf.matmul(hidden2, weights) + biases\n",
    "  tf.add_to_collection(\"logits\", logits)\n",
    "\n",
    "init_all_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Initializes all the variables.\n",
    "  sess.run(init_all_op)\n",
    "  # Runs to logit.\n",
    "  sess.run(logits)\n",
    "  # Creates a saver.\n",
    "  saver0 = tf.train.Saver()\n",
    "  saver0.save(sess, 'my-save-dir/my-model-10000')\n",
    "  # Generates MetaGraphDef.\n",
    "  saver0.export_meta_graph('my-save-dir/my-model-10000.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import it and extend it to a training graph.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  new_saver = tf.train.import_meta_graph('my-save-dir/my-model-10000.meta')\n",
    "  new_saver.restore(sess, 'my-save-dir/my-model-10000')\n",
    "  # Addes loss and train.\n",
    "  labels = tf.constant(0, tf.int32, shape=[100], name=\"labels\")\n",
    "  batch_size = tf.size(labels)\n",
    "  labels = tf.expand_dims(labels, 1)\n",
    "  indices = tf.expand_dims(tf.range(0, batch_size), 1)\n",
    "  concated = tf.concat([indices, labels], 1)\n",
    "  onehot_labels = tf.sparse_to_dense(\n",
    "      concated, tf.stack([batch_size, 10]), 1.0, 0.0)\n",
    "  logits = tf.get_collection(\"logits\")[0]\n",
    "  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "      labels=onehot_labels, logits=logits, name=\"xentropy\")\n",
    "  loss = tf.reduce_mean(cross_entropy, name=\"xentropy_mean\")\n",
    "\n",
    "  tf.summary.scalar('loss', loss)\n",
    "  # Creates the gradient descent optimizer with the given learning rate.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "\n",
    "  # Runs train_op.\n",
    "  train_op = optimizer.minimize(loss)\n",
    "  sess.run(train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import a graph with preset devices.\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  new_saver = tf.train.import_meta_graph('my-save-dir/my-model-10000.meta',\n",
    "      clear_devices=True)\n",
    "  new_saver.restore(sess, 'my-save-dir/my-model-10000')\n",
    "  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import within the default graph.\n",
    "\n",
    "meta_graph_def = tf.train.export_meta_graph()\n",
    "...\n",
    "tf.reset_default_graph()\n",
    "...\n",
    "tf.train.import_meta_graph(meta_graph_def)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Retrieve Hyper Parameters\n",
    "filename = \".\".join([tf.train.latest_checkpoint(train_dir), \"meta\"])\n",
    "tf.train.import_meta_graph(filename)\n",
    "hparams = tf.get_collection(\"hparams\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
