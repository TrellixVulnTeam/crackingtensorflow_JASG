{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_tf_random_seed': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x10d0c3690>, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_task_id': 0, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_evaluation_master': '', '_keep_checkpoint_every_n_hours': 10000, '_master': ''}\n",
      "WARNING:tensorflow:From /Users/lipingzhang/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.17298, step = 1\n",
      "INFO:tensorflow:global_step/sec: 1176.13\n",
      "INFO:tensorflow:loss = 0.173284, step = 101\n",
      "INFO:tensorflow:global_step/sec: 1340.8\n",
      "INFO:tensorflow:loss = 0.112588, step = 201\n",
      "INFO:tensorflow:global_step/sec: 1293.85\n",
      "INFO:tensorflow:loss = 0.081251, step = 301\n",
      "INFO:tensorflow:global_step/sec: 1311.18\n",
      "INFO:tensorflow:loss = 0.071414, step = 401\n",
      "INFO:tensorflow:global_step/sec: 1330.47\n",
      "INFO:tensorflow:loss = 0.0645444, step = 501\n",
      "INFO:tensorflow:global_step/sec: 1344.99\n",
      "INFO:tensorflow:loss = 0.0594761, step = 601\n",
      "INFO:tensorflow:global_step/sec: 1329.82\n",
      "INFO:tensorflow:loss = 0.0565678, step = 701\n",
      "INFO:tensorflow:global_step/sec: 1317.54\n",
      "INFO:tensorflow:loss = 0.0535153, step = 801\n",
      "INFO:tensorflow:global_step/sec: 1326.58\n",
      "INFO:tensorflow:loss = 0.0515885, step = 901\n",
      "INFO:tensorflow:global_step/sec: 1317.51\n",
      "INFO:tensorflow:loss = 0.0500845, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 1308.78\n",
      "INFO:tensorflow:loss = 0.0486503, step = 1101\n",
      "INFO:tensorflow:global_step/sec: 1278.71\n",
      "INFO:tensorflow:loss = 0.0474363, step = 1201\n",
      "INFO:tensorflow:global_step/sec: 1201.6\n",
      "INFO:tensorflow:loss = 0.0455893, step = 1301\n",
      "INFO:tensorflow:global_step/sec: 1304.31\n",
      "INFO:tensorflow:loss = 0.0448189, step = 1401\n",
      "INFO:tensorflow:global_step/sec: 1304.39\n",
      "INFO:tensorflow:loss = 0.0446906, step = 1501\n",
      "INFO:tensorflow:global_step/sec: 1327.69\n",
      "INFO:tensorflow:loss = 0.0424548, step = 1601\n",
      "INFO:tensorflow:global_step/sec: 1310.14\n",
      "INFO:tensorflow:loss = 0.0430387, step = 1701\n",
      "INFO:tensorflow:global_step/sec: 1303.1\n",
      "INFO:tensorflow:loss = 0.0409709, step = 1801\n",
      "INFO:tensorflow:global_step/sec: 1269.55\n",
      "INFO:tensorflow:loss = 0.0401204, step = 1901\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.0429132.\n",
      "WARNING:tensorflow:From /Users/lipingzhang/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-10-25-22:14:33\n",
      "INFO:tensorflow:Evaluation [1/1]\n",
      "INFO:tensorflow:Finished evaluation at 2017-10-25-22:14:34\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.966667, auc = 0.998333, global_step = 2000, loss = 0.0736693\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n",
      "\n",
      " Test accuracy: 0.966667\n",
      "\n",
      "New sample, class predictions: [1, 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# high level machine learning API(tf.contrib.learn)\n",
    "import tensorflow as tf\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    # if the training and test sets aren't stored locally, download them\n",
    "    if not os.path.exists(IRIS_TRAINING):\n",
    "        raw = urllib.urlopen(IRIS_TRAINING_URL).read()\n",
    "        with open(IRIS_TRAINING, \"w\") as f:\n",
    "            f.write(raw)\n",
    "        \n",
    "    if not os.path.exists(IRIS_TEST):\n",
    "        raw = urllib.urlopen(IRIS_TEST_URL).read()\n",
    "        with open(IRIS_TEST, \"w\") as f:\n",
    "            f.write(raw)\n",
    "    \n",
    "    # load datasets\n",
    "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=IRIS_TRAINING,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32)\n",
    "    \n",
    "    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "        filename=IRIS_TEST,\n",
    "        target_dtype=np.int,\n",
    "        features_dtype=np.float32)\n",
    "    \n",
    "    # specify that all features have real-value date\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=4)]\n",
    "    \n",
    "    # builder 3 layer DNN with 10, 20, 10 units respectively.\n",
    "    classifier = tf.contrib.learn.DNNClassifier(feature_columns=feature_columns,\n",
    "                                               hidden_units=[10,20,10],\n",
    "                                               n_classes=3,\n",
    "                                               model_dir=\"/tmp/iris_model\")\n",
    "    \n",
    "    # define the training inputs\n",
    "    def get_train_inputs():\n",
    "        x = tf.constant(training_set.data)\n",
    "        y = tf.constant(training_set.target)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    # fit model\n",
    "    classifier.fit(input_fn=get_train_inputs, steps=2000)\n",
    "    \n",
    "    # define the test inputs\n",
    "    def get_test_inputs():\n",
    "        x = tf.constant(test_set.data)\n",
    "        y = tf.constant(test_set.target)\n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    # evaluate accuracy\n",
    "    accuracy_score = classifier.evaluate(input_fn=get_test_inputs,\n",
    "                                        steps=1)[\"accuracy\"]\n",
    "    print(\"\\n Test accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "    \n",
    "    # classfy two new flower samples\n",
    "    def new_samples():\n",
    "        return np.array(\n",
    "        [[6.4, 3.2, 4.5, 1.5],\n",
    "        [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
    "    \n",
    "    predictions = list(classifier.predict(input_fn=new_samples))\n",
    "    \n",
    "    print(\n",
    "        \"New sample, class predictions: {}\\n\"\n",
    "        .format(predictions))\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}