{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-7f9fd40e2a2e>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-7f9fd40e2a2e>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    classifier = ...\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#Reading data\n",
    "\n",
    "with tf.Session():\n",
    "  input = tf.placeholder(tf.float32)\n",
    "  classifier = ...\n",
    "  print(classifier.eval(feed_dict={input: my_python_preprocessing_fn()}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename_queue = tf.train.string_input_producer([\"file0.csv\", \"file1.csv\"])\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "# Default values, in case of empty columns. Also specifies the type of the\n",
    "# decoded result.\n",
    "record_defaults = [[1], [1], [1], [1], [1]]\n",
    "col1, col2, col3, col4, col5 = tf.decode_csv(\n",
    "    value, record_defaults=record_defaults)\n",
    "features = tf.stack([col1, col2, col3, col4])\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  # Start populating the filename queue.\n",
    "  coord = tf.train.Coordinator()\n",
    "  threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "  for i in range(1200):\n",
    "    # Retrieve a single instance:\n",
    "    example, label = sess.run([features, col5])\n",
    "\n",
    "  coord.request_stop()\n",
    "  coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_my_file_format(filename_queue):\n",
    "  reader = tf.SomeReader()\n",
    "  key, record_string = reader.read(filename_queue)\n",
    "  example, label = tf.some_decoder(record_string)\n",
    "  processed_example = some_processing(example)\n",
    "  return processed_example, label\n",
    "\n",
    "def input_pipeline(filenames, batch_size, num_epochs=None):\n",
    "  filename_queue = tf.train.string_input_producer(\n",
    "      filenames, num_epochs=num_epochs, shuffle=True)\n",
    "  example, label = read_my_file_format(filename_queue)\n",
    "  # min_after_dequeue defines how big a buffer we will randomly sample\n",
    "  #   from -- bigger means better shuffling but slower start up and more\n",
    "  #   memory used.\n",
    "  # capacity must be larger than min_after_dequeue and the amount larger\n",
    "  #   determines the maximum we will prefetch.  Recommendation:\n",
    "  #   min_after_dequeue + (num_threads + a small safety margin) * batch_size\n",
    "  min_after_dequeue = 10000\n",
    "  capacity = min_after_dequeue + 3 * batch_size\n",
    "  example_batch, label_batch = tf.train.shuffle_batch(\n",
    "      [example, label], batch_size=batch_size, capacity=capacity,\n",
    "      min_after_dequeue=min_after_dequeue)\n",
    "  return example_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#need more parallelism or shuffling of examples between files\n",
    "def read_my_file_format(filename_queue):\n",
    "  # Same as above\n",
    "\n",
    "def input_pipeline(filenames, batch_size, read_threads, num_epochs=None):\n",
    "  filename_queue = tf.train.string_input_producer(\n",
    "      filenames, num_epochs=num_epochs, shuffle=True)\n",
    "  example_list = [read_my_file_format(filename_queue)\n",
    "                  for _ in range(read_threads)]\n",
    "  min_after_dequeue = 10000\n",
    "  capacity = min_after_dequeue + 3 * batch_size\n",
    "  example_batch, label_batch = tf.train.shuffle_batch_join(\n",
    "      example_list, batch_size=batch_size, capacity=capacity,\n",
    "      min_after_dequeue=min_after_dequeue)\n",
    "  return example_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the graph, etc.\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Create a session for running operations in the Graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize the variables (like the epoch counter).\n",
    "sess.run(init_op)\n",
    "\n",
    "# Start input enqueue threads.\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "try:\n",
    "    while not coord.should_stop():\n",
    "        # Run training steps or whatever\n",
    "        sess.run(train_op)\n",
    "\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print('Done training -- epoch limit reached')\n",
    "finally:\n",
    "    # When done, ask the threads to stop.\n",
    "    coord.request_stop()\n",
    "\n",
    "# Wait for threads to finish.\n",
    "coord.join(threads)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = ...\n",
    "training_labels = ...\n",
    "with tf.Session():\n",
    "  input_data = tf.constant(training_data)\n",
    "  input_labels = tf.constant(training_labels)\n",
    "  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = ...\n",
    "training_labels = ...\n",
    "with tf.Session() as sess:\n",
    "  data_initializer = tf.placeholder(dtype=training_data.dtype,\n",
    "                                    shape=training_data.shape)\n",
    "  label_initializer = tf.placeholder(dtype=training_labels.dtype,\n",
    "                                     shape=training_labels.shape)\n",
    "  input_data = tf.Variable(data_initializer, trainable=False, collections=[])\n",
    "  input_labels = tf.Variable(label_initializer, trainable=False, collections=[])\n",
    "  ...\n",
    "  sess.run(input_data.initializer,\n",
    "           feed_dict={data_initializer: training_data})\n",
    "  sess.run(input_labels.initializer,\n",
    "           feed_dict={label_initializer: training_labels})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
